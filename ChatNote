import streamlit as st
from PyPDF2 import PdfReader
from langchain.chains.question_answering import load_qa_chain
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.chat_models import ChatOpenAI
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS

OpenAI_API_KEY = "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"

st.header("ChatNote")

with st.sidebar:
    st.title("My notes")
    file=st.file_uploader("Upload your PDF notes and start asking questions ",type="pdf")

if file is not None:
    my_pdf=PdfReader(file)
    text=""
    for page in my_pdf.pages:
        text += page.extract_text()
       # st.write(text)

        # break it into Chunks
    # Corrected 'seperators' to 'separators'
    splitter = RecursiveCharacterTextSplitter(separators=["\n"],chunk_size=250,chunk_overlap=50)
    chunks=splitter.split_text(text)
    #st.write(chunks)

    embeddings=OpenAIEmbeddings(api_key=OpenAI_API_KEY)

    vector_store=FAISS.from_texts(chunks,embeddings)

    #get user query
    user_query=st.text_input("Type your query here ")

    #semantic search from vector store
    if user_query:
        matching_chunks=vector_store.similarity_search(user_query)

        #define our llm
        llm=ChatOpenAI(
            api_key=OpenAI_API_KEY,
            max_tokens=300,
            temperature=0,
            model="gpt-3.5-turbo"

        )
        #Generate Response

        chain=load_qa_chain(llm,chain_type="stuff")
        output=chain.run(question=user_query,input_documents=matching_chunks)
        st.write(output)
